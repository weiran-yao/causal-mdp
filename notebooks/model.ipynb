{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Probablistic Physical Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.nn import MetaLayer\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fully_connected_edge_index(n_objects):\n",
    "    n_relations  = n_objects * (n_objects - 1)\n",
    "    edge_index = torch.zeros((2, n_relations), dtype=torch.long)\n",
    "    count = 0\n",
    "    for i in range(n_objects):\n",
    "        for j in range(n_objects):\n",
    "            if(i != j):\n",
    "                edge_index[0, count] = i\n",
    "                edge_index[1, count] = j\n",
    "                count += 1\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = create_fully_connected_edge_index(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeModel(nn.Module):\n",
    "    def __init__(self, node_dims, edge_dims, u_dims, hidden_size=32):\n",
    "        super(EdgeModel, self).__init__()\n",
    "        input_size = 2*node_dims+edge_dims\n",
    "        self.edge_mlp = Seq(Lin(input_size, hidden_size), ReLU(), Lin(hidden_size, edge_dims))\n",
    "\n",
    "    def forward(self, src, dest, edge_attr, u, batch):\n",
    "        # source, target: [E, F_x], where E is the number of edges.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u], where B is the number of graphs.\n",
    "        # batch: [E] with max entry B - 1.\n",
    "        out = torch.cat([src, dest, edge_attr], dim=-1)\n",
    "        return self.edge_mlp(out)\n",
    "\n",
    "class NodeModel(torch.nn.Module):\n",
    "    def __init__(self, node_dims, edge_dims, u_dims, hidden_size=32):\n",
    "        super(NodeModel, self).__init__()\n",
    "        mlp_1_input_size = node_dims+edge_dims\n",
    "        self.node_mlp_1 = Seq(Lin(mlp_1_input_size, hidden_size), ReLU(), Lin(hidden_size, hidden_size))\n",
    "        mlp_2_input_size = node_dims+hidden_size\n",
    "        self.node_mlp_2 = Seq(Lin(mlp_2_input_size, hidden_size), ReLU(), Lin(hidden_size, node_dims))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        row, col = edge_index\n",
    "        out = torch.cat([x[row], edge_attr], dim=-1)\n",
    "        out = self.node_mlp_1(out)\n",
    "        out = scatter_mean(out, col, dim=1, dim_size=x.size(1))\n",
    "        out = torch.cat([x, out], dim=-1)\n",
    "        return self.node_mlp_2(out)\n",
    "\n",
    "class GlobalModel(torch.nn.Module):\n",
    "    def __init__(self, node_dims, u_dims, hidden_size=32):\n",
    "        super(GlobalModel, self).__init__()\n",
    "        input_size = node_dims\n",
    "        self.global_mlp = Seq(Lin(input_size, hidden_size), ReLU(), Lin(hidden_size, u_dims))\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, u, batch):\n",
    "        # x: [N, F_x], where N is the number of nodes.\n",
    "        # edge_index: [2, E] with max entry N - 1.\n",
    "        # edge_attr: [E, F_e]\n",
    "        # u: [B, F_u]\n",
    "        # batch: [N] with max entry B - 1.\n",
    "        out = torch.mean(x, dim=1, keepdim=False)\n",
    "        #out = scatter_mean(x, batch, dim=0)\n",
    "        return self.global_mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLSTMRecgnition(nn.Module):\n",
    "    def __init__(self, hidden_size=16):\n",
    "        super().__init__()\n",
    "        ## GNN ##\n",
    "        self.node_dims = 7+2 #X+y\n",
    "        self.hidden_size=hidden_size\n",
    "        self.edge_dims=hidden_size\n",
    "        self.u_dims=hidden_size \n",
    "        edge_model = EdgeModel(self.node_dims, self.edge_dims, self.u_dims, self.hidden_size)\n",
    "        node_model = NodeModel(self.node_dims, self.edge_dims, self.u_dims, self.hidden_size)\n",
    "        global_model = GlobalModel(self.node_dims, self.u_dims, self.hidden_size)\n",
    "        self.op = MetaLayer(edge_model, node_model, global_model)\n",
    "        ## LSTM ##\n",
    "        self.edge_rnn = nn.LSTM(self.edge_dims, self.hidden_size, batch_first=True)\n",
    "        self.node_rnn = nn.LSTM(self.node_dims, self.hidden_size, batch_first=True)\n",
    "        self.global_rnn = nn.LSTM(self.u_dims, self.hidden_size, batch_first=True)\n",
    "        ## Linear ##\n",
    "        self.edge_fc_1 = nn.Linear(self.hidden_size, 2)\n",
    "        self.edge_fc_2 = nn.Linear(self.hidden_size, 2)\n",
    "        self.node_fc_1 = nn.Linear(self.hidden_size, 2)\n",
    "        self.node_fc_2 = nn.Linear(self.hidden_size, 2)\n",
    "        self.global_fc_1 = nn.Linear(self.hidden_size, 2)\n",
    "        self.global_fc_2 = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define the forward computation on the latent z\n",
    "        # x shape: [n_experiments, steps, nodes, node_dims]\n",
    "        bs, steps, nodes, node_dims = x.size()\n",
    "        edge_index = create_fully_connected_edge_index(nodes)\n",
    "        _, edges = edge_index.size()\n",
    "        x_reshape = x.view(-1, nodes, node_dims)\n",
    "        node_attr, edge_attr, global_attr = op(x_reshape, edge_index)\n",
    "        node_attr = node_attr.view(bs, steps, nodes, self.node_dims).permute(0,2,1,3)\n",
    "        edge_attr = edge_attr.view(bs, steps, edges, self.edge_dims).permute(0,2,1,3)\n",
    "        global_attr = global_attr.view(bs, steps, self.u_dims)\n",
    "        node_attr = node_attr.view(-1, steps, self.node_dims)\n",
    "        edge_attr = edge_attr.view(-1, steps, self.edge_dims)\n",
    "        # RNN forward\n",
    "        node_out, _ = self.node_rnn(node_attr)\n",
    "        edge_out, _ = self.edge_rnn(edge_attr)\n",
    "        global_out, _ = self.global_rnn(global_attr)\n",
    "        node_out  = node_out[:,-1]\n",
    "        edge_out = edge_out[:,-1]\n",
    "        global_out = global_out[:,-1]\n",
    "        # FC forward\n",
    "        z_node_mu = self.node_fc_1(node_out).view(bs, nodes, -1)\n",
    "        z_node_logvar = self.node_fc_2(node_out).view(bs, nodes, -1)\n",
    "        z_edge_mu = self.edge_fc_1(edge_out).view(bs, edges, -1)\n",
    "        z_edge_logvar = self.edge_fc_2(edge_out).view(bs, edges, -1)\n",
    "        z_global_mu = self.global_fc_1(global_out).view(bs, -1)\n",
    "        z_global_logvar = self.global_fc_2(global_out).view(bs, -1)\n",
    "        return [z_node_mu, z_node_logvar, z_edge_mu, z_edge_logvar, z_global_mu, z_global_logvar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationalModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(RelationalModel, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x: [batch_size, n_relations, input_size]\n",
    "        Returns:\n",
    "            [batch_size, n_relations, output_size]\n",
    "        '''\n",
    "        batch_size, n_relations, input_size = x.size()\n",
    "        x = x.view(-1, input_size)\n",
    "        x = self.layers(x)\n",
    "        x = x.view(batch_size, n_relations, self.output_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ObjectModel, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 2), #speedX and speedY\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Args:\n",
    "            x: [batch_size, n_objects, input_size]\n",
    "        Returns:\n",
    "            [batch_size * n_objects, 2] speedX and speedY\n",
    "        '''\n",
    "        input_size = x.size(2)\n",
    "        x = x.view(-1, input_size)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros((3,3))\n",
    "b = torch.ones((1,1)).repeat(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionNetworkGenerator(nn.Module):\n",
    "    def __init__(self, effect_dims=4, hidden_size=128):\n",
    "        super().__init__()\n",
    "        # setup the two linear transformations used\n",
    "        self.node_dims = 7+2 #X+z_node\n",
    "        self.z_edge_dims = 2\n",
    "        self.z_u_dims = 2\n",
    "        self.effect_dims = effect_dims\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relational_model = RelationalModel(2*self.node_dims + self.z_edge_dims, \n",
    "                                                self.effect_dims, self.hidden_size)\n",
    "        self.object_model     = ObjectModel(self.node_dims+self.effect_dims+self.z_u_dims,\n",
    "                                            self.hidden_size)\n",
    "    def forward(self, x, z):\n",
    "        # x shape: [bs, steps, nodes, node_dims]\n",
    "        bs, steps, nodes, node_dims = x.size()\n",
    "        edge_index = create_fully_connected_edge_index(nodes)\n",
    "        sender_relations = F.one_hot(edge_index[0]).T.unsqueeze(0).repeat(bs*steps,1,1)\n",
    "        receiver_relations = F.one_hot(edge_index[1]).T.unsqueeze(0).repeat(bs*steps,1,1)\n",
    "        _, edges = edge_index.size()\n",
    "        row, col = edge_index\n",
    "        # define the forward computation on the latent z\n",
    "        z_node, z_edge, z_global = z\n",
    "        z_node = torch.unsqueeze(z_node, dim=1).repeat(1, steps, 1, 1)\n",
    "        z_edge = z_edge.repeat(steps, 1, 1)\n",
    "        z_global = torch.unsqueeze(z_global, dim=1).repeat(steps, nodes, 1)\n",
    "        x = torch.cat((x, z_node), dim=-1).view(bs*steps, nodes, -1)\n",
    "        senders   = sender_relations.permute(0, 2, 1).bmm(x)\n",
    "        receivers = receiver_relations.permute(0, 2, 1).bmm(x)\n",
    "        effects = self.relational_model(torch.cat([senders, receivers, z_edge], -1))\n",
    "        effect_receivers = receiver_relations.bmm(effects)\n",
    "        # predicted shape [bs*steps, nodes, 2]\n",
    "        predicted = self.object_model(torch.cat([x, z_global,effect_receivers], -1))\n",
    "        return predicted.view(bs, steps, nodes, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsVAE(nn.Module):\n",
    "    # by default our latent space is 50-dimensional\n",
    "    # and we use 400 hidden units\n",
    "    def __init__(self, z_dim=2, use_cuda=False):\n",
    "        super().__init__()\n",
    "        # create the encoder and decoder networks\n",
    "        self.encoder = GNNLSTMRecgnition()\n",
    "        self.decoder = InteractionNetworkGenerator()\n",
    "\n",
    "        if use_cuda:\n",
    "            # calling cuda() here will put all the parameters of\n",
    "            # the encoder and decoder networks into gpu memory\n",
    "            self.cuda()\n",
    "        self.use_cuda = use_cuda\n",
    "        self.z_dim = z_dim\n",
    "    \n",
    "    def encode(self, xy):\n",
    "        return self.encoder(xy)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, x, z):\n",
    "        return self.decoder(x, z)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        xy = torch.cat((x, y), dim=-1)\n",
    "        z_stats = self.encode(xy)\n",
    "        z_node_mu, z_node_logvar, z_edge_mu, z_edge_logvar, z_global_mu, z_global_logvar = z_stats\n",
    "        z_node = self.reparameterize(z_node_mu, z_node_logvar)\n",
    "        z_edge = self.reparameterize(z_edge_mu, z_edge_logvar)\n",
    "        z_global = self.reparameterize(z_global_mu, z_global_logvar)\n",
    "        z_sample = [z_node, z_edge, z_global]\n",
    "        return self.decode(x, z_sample), mu, logvar\n",
    "    # define the model p(x|z)p(z)\n",
    "    def model(self, x):\n",
    "        # register PyTorch module `decoder` with Pyro\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # setup hyperparameters for prior p(z)\n",
    "            z_loc = x.new_zeros(torch.Size((x.shape[0], self.z_dim)))\n",
    "            z_scale = x.new_ones(torch.Size((x.shape[0], self.z_dim)))\n",
    "            # sample from prior (value will be sampled by guide when computing the ELBO)\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            # decode the latent code z\n",
    "            loc_img = self.decoder.forward(z)\n",
    "            # score against actual images\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(loc_img).to_event(1), obs=x.reshape(-1, 784))\n",
    "\n",
    "    # define the guide (i.e. variational distribution) q(z|x)\n",
    "    def guide(self, x):\n",
    "        # register PyTorch module `encoder` with Pyro\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            # use the encoder to get the parameters used to define q(z|x)\n",
    "            z_loc, z_scale = self.encoder.forward(x)\n",
    "            # sample the latent code z\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "\n",
    "    # define a helper function for reconstructing images\n",
    "    def reconstruct_img(self, x):\n",
    "        # encode image x\n",
    "        z_loc, z_scale = self.encoder(x)\n",
    "        # sample in latent space\n",
    "        z = dist.Normal(z_loc, z_scale).sample()\n",
    "        # decode the image (note we don't sample in image space)\n",
    "        loc_img = self.decoder(z)\n",
    "        return loc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch15",
   "language": "python",
   "name": "torch15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
